import findspark
findspark.init('/home/ubuntu/spark-3.2.1-bin-hadoop2.7')
import pyspark
from pyspark.sql import SparkSession

spark = SparkSession.builder.appName("BusBreakdowns").getOrCreate()

# Read the file
file = "Bus_Breakdown_and_Delays.csv"
df = spark.read.csv(file, header=True, inferSchema=True)

spark.conf.set("spark.sql.repl.eagerEval.enabled", True)
df.limit(5).show()

# Show info
df.printSchema()
